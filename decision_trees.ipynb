{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download historical data from EIA and NOAA/GHCN-d to the local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import download_historical_data as dl\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing some stuff from the FastAI book\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "import fastai.tabular.all as aiTab\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "import dtreeviz.trees as dtrees\n",
    "from IPython.display import Image, display_svg, SVG\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_columns = 6\n",
    "\n",
    "HISTORICAL_DATA_DIR = os.path.abspath(\"./historical_data\")\n",
    "ANALYSIS_DATA_DIR = os.path.abspath(\"./analysis_data/\")\n",
    "ELECTRIC_DATA_DIR = os.path.join(HISTORICAL_DATA_DIR, \"electric_data\")\n",
    "WEATHER_DATA_DIR = os.path.join(HISTORICAL_DATA_DIR, \"weather_station_data\")\n",
    "\n",
    "for dir in [HISTORICAL_DATA_DIR, ANALYSIS_DATA_DIR, ELECTRIC_DATA_DIR, WEATHER_DATA_DIR]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "\n",
    "WEATHER_STATION_IDS = [\n",
    "    \"USW00023066\",  # Grand Junction Walker Field\n",
    "    \"USC00053553\",  # Greeley UNC\n",
    "    \"USC00053005\",  # Ft Collins\n",
    "    \"USC00050848\",  # Boulder\n",
    "    \"USC00055984\",  # Northglenn\n",
    "    \"USC00058995\",  # Wheat Ridge\n",
    "    \"USW00023061\"  # Alamosa\n",
    "]\n",
    "\n",
    "# Uncomment following lines to force re-download of source data\n",
    "# Otherwise can also run the download script manually via: python download_historical_data.py\n",
    "# Data files are saved locally so you only need to re-download to get new/different data\n",
    "\n",
    "#dl.download_eia_historical_data(ELECTRIC_DATA_DIR, eia_respondent=\"PSCO\")\n",
    "#dl.download_ghcnd_historical_data(WEATHER_DATA_DIR, WEATHER_STATION_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "plt.style.use(\"default\") #alternative \"ggplot\"\n",
    "\n",
    "temp_df : pd.DataFrame = None\n",
    "\n",
    "## Load up temperature data for each weather station, into their own columns\n",
    "for df_file in glob.glob(WEATHER_DATA_DIR + \"\\*.json\"):\n",
    "    with open(df_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        station_id = os.path.basename(df_file)[0:11]\n",
    "        station_df = pd.read_json(f)\n",
    "        station_df.index.rename(\"date\", inplace=True)\n",
    "        \n",
    "        # TODO: This name-mangling seems like a halfassed way to either do a MultiIndex or maybe a tuple-index\n",
    "        # Going to leave it for now as I'm not clear what will be easiest when trying to train an ML model\n",
    "        col_renames = {col: f\"{station_id}_{col}\" for col in station_df.columns}\n",
    "        station_df.rename(col_renames, axis=\"columns\", inplace=True)\n",
    "        \n",
    "        if temp_df is not None:\n",
    "            temp_df = pd.merge(left=temp_df, right=station_df, how=\"outer\", left_index=True, right_index=True)\n",
    "        else:\n",
    "            temp_df = station_df\n",
    "\n",
    "len(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PSCO electric demand data from EIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psco_demand_data_file = os.path.join(ELECTRIC_DATA_DIR, \"psco-daily-dataframe.json\")\n",
    "with open(psco_demand_data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand_df = pd.read_json(f)\n",
    "\n",
    "len(demand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge demand and temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.merge(demand_df, temp_df, how=\"outer\", left_index=True, right_index=True)\n",
    "joined_df.dropna(inplace=True)\n",
    "len(joined_df),joined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment data with new dates and maybe some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Augment data\n",
    "augmented_df = joined_df.copy()\n",
    "\n",
    "# Extract date index into a column\n",
    "augmented_df.reset_index(inplace=True)\n",
    "augmented_df[\"date\"] = augmented_df[\"index\"]  \n",
    "augmented_df.set_index(\"index\", inplace=True)\n",
    "\n",
    "## Adds date parts\n",
    "augmented_df = aiTab.add_datepart(augmented_df, \"date\", drop=True)\n",
    "## But a lot of the augmented parts are not that applicable in our case\n",
    "augmented_df.drop(['Elapsed', 'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start',\n",
    "                   'Is_year_end', 'Is_year_start'], axis=1, inplace=True)\n",
    "\n",
    "## Add lagged values\n",
    "# for lag in range(1, 15):\n",
    "#     augmented_df[f\"demand_lag_{lag}\"] = augmented_df[\"daily_demand\"].shift(lag)\n",
    "\n",
    "augmented_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for data sets\n",
    "train_mask = (augmented_df.Year < 2021)\n",
    "validation_mask = ((augmented_df.Year >= 2021) & (augmented_df.Year < 2022))\n",
    "test_mask = (augmented_df.Year >= 2022)\n",
    "\n",
    "## Split out training, test and validation sets\n",
    "train_df = augmented_df.where(train_mask).dropna()\n",
    "validation_df = augmented_df.where(validation_mask).dropna()\n",
    "test_df = augmented_df.where(test_mask).dropna()\n",
    "\n",
    "# print(train_df.iloc[0:5][[\"daily_demand\"]])\n",
    "# print(validation_df.iloc[0:5][[\"daily_demand\"]])\n",
    "# print(test_df.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create indexes from the sets\n",
    "train_idx = np.where(train_mask)[0]\n",
    "valid_idx = np.where(validation_mask)[0]\n",
    "test_idx = np.where(test_mask)[0]\n",
    "print(f\"trainSize={len(train_idx)}, validationSize={len(valid_idx)}, testSize={len(test_idx)}\")\n",
    "# print(train_idx[0:5])\n",
    "# print(valid_idx[0:5])\n",
    "# print(test_idx[0:5])\n",
    "\n",
    "splits = (list(train_idx), list(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split out categorical vs continuous data\n",
    "cont, cat = aiTab.cont_cat_split(augmented_df, 1, dep_var=\"daily_demand\")\n",
    "print(cont)\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create TabularPandas\n",
    "procs = [aiTab.Categorify, aiTab.FillMissing]\n",
    "dep_var = \"daily_demand\"\n",
    "to = aiTab.TabularPandas(augmented_df, procs, cat, cont, y_names=dep_var, splits=splits)\n",
    "len(to.train),len(to.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiTab.save_pickle(os.path.join(ANALYSIS_DATA_DIR, 'tabular.pkl'), to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload from pickle\n",
    "to = aiTab.load_pickle(os.path.join(ANALYSIS_DATA_DIR, 'tabular.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick out the validation input and output data (and duplicate that effect with the test Dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,y = to.train.xs,to.train.y\n",
    "valid_xs,valid_y = to.valid.xs,to.valid.y\n",
    "test_xs = test_df.drop(\"daily_demand\", axis=1, inplace=False)\n",
    "test_y = test_df[\"daily_demand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a decision tree\n",
    "tree = DecisionTreeRegressor(max_leaf_nodes=4)\n",
    "tree.fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import re\n",
    "\n",
    "def draw_tree(t, df, size=10, ratio=0.6, precision=0, **kwargs):\n",
    "    s = export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n",
    "                        special_characters=True, rotate=False, precision=precision, **kwargs)\n",
    "    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))\n",
    "\n",
    "\n",
    "# Draw the tree\n",
    "draw_tree(tree, xs, size=10, leaves_parallel=True, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see that in DTreeViz\n",
    "samp_idx = np.random.permutation(len(y))[:500]\n",
    "dtrees.dtreeviz(tree, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n",
    "         fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n",
    "         orientation='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MOAR LEAVES\n",
    "tree = DecisionTreeRegressor(min_samples_leaf=15)\n",
    "tree.fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to check root-mean-squared error for the model\n",
    "import math\n",
    "def r_mse(pred, y): return round(math.sqrt(((pred - y)**2).mean()), 6)\n",
    "def m_rmse(m, xs, y): return r_mse(m.predict(xs), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check error in the training set\n",
    "m_rmse(tree, xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check RMS error against validation set\n",
    "m_rmse(tree, valid_xs, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many leaves do we have? Oh, it's one per measurement, so massively overfitted\n",
    "tree.get_n_leaves(), len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the full tree (use carefully, it's pretty big)\n",
    "# samp_idx = np.random.permutation(len(y))[:500]\n",
    "# dtrees.dtreeviz(tree, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,\n",
    "#                 fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n",
    "#                 orientation='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to grow a random forest with some default parameters chosen\n",
    "\n",
    "## n_estimators -> number of trees in the forest\n",
    "num_estimators = 200\n",
    "\n",
    "def grow_random_forest(xs, y, n_estimators=num_estimators, max_samples=0.8,\n",
    "       max_features=0.5, min_samples_leaf=4, **kwargs):\n",
    "   m = RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n",
    "                                 max_samples=max_samples, max_features=max_features,\n",
    "                                 min_samples_leaf=min_samples_leaf, oob_score=True)\n",
    "   return m.fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = grow_random_forest(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rmse(forest, xs, y), m_rmse(forest, valid_xs, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get predictions from each individual tree in the forest\n",
    "preds = np.stack([t.predict(valid_xs) for t in forest.estimators_])\n",
    "\n",
    "## Plot the mean error for a given number of estimators used\n",
    "plt.plot([r_mse(preds[:i + 1].mean(0), valid_y) for i in range(num_estimators)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of-bag errors for the forest\n",
    "r_mse(forest.oob_prediction_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the standard deviation of the estimates from each tree, for each row in the validation set\n",
    "preds_std = preds.std(0)\n",
    "\n",
    "#std dev for the first 5 rows\n",
    "preds_std[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_importance(m, df):\n",
    "    return pd.DataFrame({'cols': df.columns, 'imp': m.feature_importances_}\n",
    "                        ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feature_importance(forest, xs)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(fi):\n",
    "    return fi.plot('cols', 'imp', 'barh', figsize=(12, 7), legend=False)\n",
    "\n",
    "\n",
    "plot_feature_importance(fi[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trim out some low-importance columns\n",
    "to_keep = fi[fi.imp > 0.005].cols\n",
    "len(fi.cols),len(to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new & improved datasets (without the low-importance columns)\n",
    "xs_imp = xs[to_keep]\n",
    "valid_xs_imp = valid_xs[to_keep]\n",
    "test_xs_imp = test_xs[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain\n",
    "forest = grow_random_forest(xs_imp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retest\n",
    "m_rmse(forest, xs_imp, y), m_rmse(forest, valid_xs_imp, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replot feature importance\n",
    "plot_feature_importance(rf_feature_importance(forest, xs_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to draw rank importance diagrams, stolen from the FastAI book code\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as hc\n",
    "\n",
    "def cluster_columns(df, figsize=(10, 6), font_size=12):\n",
    "    corr = np.round(scipy.stats.spearmanr(df).correlation, 4)\n",
    "    corr_condensed = hc.distance.squareform(1 - corr)\n",
    "    z = hc.linkage(corr_condensed, method='average')\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    hc.dendrogram(z, labels=df.columns, orientation='left', leaf_font_size=font_size)\n",
    "    plt.show()\n",
    "\n",
    "cluster_columns(xs_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get out-of-bag scores for a fairly simple model\n",
    "## Although this one is so fast to train that we're not going to make it any simpler\n",
    "def get_oob(df, y):\n",
    "    ## Original code from FastAI book\n",
    "    # m = RandomForestRegressor(n_estimators=40, min_samples_leaf=15,\n",
    "    #                           max_samples=50000, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "    m = grow_random_forest(df, y)\n",
    "    return m.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline\n",
    "get_oob(xs_imp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try removing potentially redundant values one at a time\n",
    "{c:get_oob(xs_imp.drop(c, axis=1), y) for c in (\n",
    "    'Week', 'Dayofyear', \n",
    "    'USC00058995_tmax', 'USC00055984_tmax',\n",
    "    'USC00053005_tmax', 'USC00050848_tmax',\n",
    "    'USC00053005_tmin', 'USC00053553_tmin',\n",
    "    \n",
    "    # This is actually our _most_ important column, but I kinda hate it for predictions.\n",
    "    # So I want to see what happens if we remove it\n",
    "    'Year'\n",
    "    )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out one from each pair of redundant columns and retest\n",
    "to_drop = ['Week', #'Dayofyear',\n",
    "           'USC00058995_tmax', #'USC00055984_tmax',\n",
    "           'USC00053005_tmax', #'USC00050848_tmax',\n",
    "           'USC00053005_tmin', #'USC00053553_tmin'\n",
    "           ]\n",
    "get_oob(xs_imp.drop(to_drop, axis=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create DFs without the redundant columns\n",
    "xs_final = xs_imp.drop(to_drop, axis=1)\n",
    "valid_xs_final = valid_xs_imp.drop(to_drop, axis=1)\n",
    "test_xs_final = test_xs_imp.drop(to_drop, axis=1)\n",
    "\n",
    "aiTab.save_pickle(os.path.join(ANALYSIS_DATA_DIR, 'xs_final.pkl'), xs_final)\n",
    "aiTab.save_pickle(os.path.join(ANALYSIS_DATA_DIR, 'valid_final.pkl'), valid_xs_final)\n",
    "aiTab.save_pickle(os.path.join(ANALYSIS_DATA_DIR, 'test_final.pkl'), test_xs_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reload data from the pickles. Unnecessary since we just created it, but we could skip the above steps if desired.\n",
    "# xs_final = aiTab.load_pickle(os.path.join(ANALYSIS_DATA_DIR, 'xs_final.pkl'))\n",
    "# valid_xs_final = aiTab.load_pickle(os.path.join(ANALYSIS_DATA_DIR, 'valid_final.pkl'))\n",
    "# test_xs_final = aiTab.load_pickle(os.path.join(ANALYSIS_DATA_DIR, 'test_final.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grow a new forst with our final dataset\n",
    "forest = grow_random_forest(xs_final, y)\n",
    "m_rmse(forest, xs_final, y), m_rmse(forest, valid_xs_final, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recheck errors\n",
    "m_rmse(forest, xs_final, y), m_rmse(forest, valid_xs_final, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the partial dependence on each variable\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "# plot_partial_dependence(forest, valid_xs_final, ['Year', 'Dayofweek'],\n",
    "#                         grid_resolution=20, ax=ax)\n",
    "plot_partial_dependence(forest, xs_final, ['Year', 'Dayofyear', 'Dayofweek'],\n",
    "                        grid_resolution=20, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waterfall_chart import plot as waterfall\n",
    "from treeinterpreter import treeinterpreter\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = valid_xs_final\n",
    "prediction,bias,contributions = treeinterpreter.predict(forest, row.values)\n",
    "prediction[0], bias[0], contributions[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the contributions of each parameter to the first row of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfall(valid_xs_final.columns, contributions[0], threshold=0.08, \n",
    "          rotation_value=90,formatting='{:,.3f}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the mean contributions of each parameter across the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode contributions into a dataframe\n",
    "contributions_df = pd.DataFrame(contributions, columns=valid_xs_final.columns)\n",
    "means = contributions_df.mean()\n",
    "waterfall(index=means.index, data=means, threshold=0.00, \n",
    "          rotation_value=90,formatting='{:,.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check errors on our test set\n",
    "#prediction, bias, contributions = treeinterpreter.predict(forest, row.values)\n",
    "m_rmse(forest, test_xs_final, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph test set predictions vs actuals\n",
    "y_pred = forest.predict(test_xs_final)\n",
    "pred_df = pd.DataFrame(data=y_pred, index=list(test_xs_final.index))\n",
    "pred_df = pred_df.join(test_y, how=\"inner\")\n",
    "pred_df.rename(columns={0: \"predicted_demand\", \"daily_demand\":\"actual_demand\"}, inplace=True)\n",
    "pred_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e-predict",
   "language": "python",
   "name": "e-predict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbc800b9954356ddf51c3c2e08059eab8570ab1b3611f475161bbcfb4053c97a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
